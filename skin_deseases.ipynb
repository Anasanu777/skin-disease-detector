{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "data_dir = \"./data\"\n",
    "metadata_file = os.path.join(data_dir, \"HAM10000_metadata.csv\")\n",
    "image_dirs = [\"HAM10000_images_part_1\", \"HAM10000_images_part_2\"]\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation & Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Loader\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {label: idx for idx, label in enumerate(self.data[\"dx\"].unique())}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx][\"image_id\"] + \".jpg\"\n",
    "        img_path = None\n",
    "        for folder in image_dirs:\n",
    "            potential_path = os.path.join(self.root_dir, folder, img_name)\n",
    "            if os.path.exists(potential_path):\n",
    "                img_path = potential_path\n",
    "                break\n",
    "        \n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"Image {img_name} not found in specified folders.\")\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.class_to_idx[self.data.iloc[idx][\"dx\"]]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = SkinDiseaseDataset(csv_file=metadata_file, root_dir=data_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GTEC\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GTEC\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained MobileNetV2 as Feature Extractor\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(128, len(dataset.class_to_idx)),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.4981\n",
      "Epoch 2/10, Loss: 1.4951\n",
      "Epoch 3/10, Loss: 1.4949\n",
      "Epoch 4/10, Loss: 1.4949\n",
      "Epoch 5/10, Loss: 1.4949\n",
      "Epoch 6/10, Loss: 1.4945\n",
      "Epoch 7/10, Loss: 1.4949\n",
      "Epoch 8/10, Loss: 1.4947\n",
      "Epoch 9/10, Loss: 1.4956\n",
      "Epoch 10/10, Loss: 1.4954\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), \"skin_disease_model.pth\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Skin Disease Class: Melanoma\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 1️⃣ Define the model architecture (ensure it matches the trained model)\n",
    "class SkinDiseaseModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes=6):  # Adjust based on trained model\n",
    "        super(SkinDiseaseModel, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=False)  # Ensure same architecture\n",
    "        self.model.classifier[1] = torch.nn.Linear(self.model.last_channel, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 2️⃣ Initialize model and load saved weights\n",
    "model = SkinDiseaseModel(num_classes=6)  # Adjust classes\n",
    "model.load_state_dict(torch.load(\"skin_disease_model.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 3️⃣ Define Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Use same normalization as training\n",
    "])\n",
    "\n",
    "# 4️⃣ Load and preprocess image\n",
    "image_path = \"data/HAM10000_images_part_2/ISIC_0029316.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0)\n",
    "\n",
    "# 5️⃣ Run the Model and Predict\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    prediction = torch.argmax(output, dim=1).item()\n",
    "\n",
    "disease_classes = {\n",
    "    0: \"Eczema\",\n",
    "    1: \"Psoriasis\",\n",
    "    2: \"Melanoma\",\n",
    "    3: \"Vitiligo\",\n",
    "    4: \"Basal Cell Carcinoma\",\n",
    "    5: \"Acne\"\n",
    "}\n",
    "\n",
    "disease_name = disease_classes.get(prediction, \"Unknown Disease\")\n",
    "print(f\"Predicted Skin Disease Class: {disease_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
